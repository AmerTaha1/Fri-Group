{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Used libraries\n",
    "import pandas as pd\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_validate\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import confusion_matrix, accuracy_score, recall_score, precision_score,\\\n",
    "                            f1_score, fbeta_score, classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1) Social Network Ads dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>15729054</td>\n",
       "      <td>Female</td>\n",
       "      <td>27</td>\n",
       "      <td>137000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>15785170</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>75000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>15570769</td>\n",
       "      <td>Female</td>\n",
       "      <td>26</td>\n",
       "      <td>80000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>335</th>\n",
       "      <td>15601550</td>\n",
       "      <td>Female</td>\n",
       "      <td>36</td>\n",
       "      <td>54000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>15789863</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Gender  Age  EstimatedSalary  Purchased\n",
       "31   15729054  Female   27           137000          1\n",
       "327  15785170  Female   42            75000          0\n",
       "10   15570769  Female   26            80000          0\n",
       "335  15601550  Female   36            54000          0\n",
       "107  15789863    Male   27            89000          0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_df=pd.read_csv('Assignment Datasets/Social_Network_Ads.csv')\n",
    "sn_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 400 entries, 0 to 399\n",
      "Data columns (total 5 columns):\n",
      " #   Column           Non-Null Count  Dtype \n",
      "---  ------           --------------  ----- \n",
      " 0   User ID          400 non-null    int64 \n",
      " 1   Gender           400 non-null    object\n",
      " 2   Age              400 non-null    int64 \n",
      " 3   EstimatedSalary  400 non-null    int64 \n",
      " 4   Purchased        400 non-null    int64 \n",
      "dtypes: int64(4), object(1)\n",
      "memory usage: 15.8+ KB\n"
     ]
    }
   ],
   "source": [
    "sn_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['Male', 'Female'], dtype=object)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_df.Gender.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>User ID</th>\n",
       "      <th>Age</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Purchased</th>\n",
       "      <th>Gender_Male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>15727696</td>\n",
       "      <td>30</td>\n",
       "      <td>135000</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>15757837</td>\n",
       "      <td>35</td>\n",
       "      <td>38000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>15746422</td>\n",
       "      <td>24</td>\n",
       "      <td>89000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      User ID  Age  EstimatedSalary  Purchased  Gender_Male\n",
       "48   15727696   30           135000          1            1\n",
       "163  15757837   35            38000          0            1\n",
       "145  15746422   24            89000          0            0"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sn_df=pd.get_dummies(sn_df, columns=['Gender'], drop_first=True)\n",
    "sn_df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    202\n",
       "1     98\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split on independent and dependent data\n",
    "X=sn_df.drop(columns=['User ID', 'Purchased'])\n",
    "y=sn_df.Purchased\n",
    "\n",
    "# Split on Train and Test parts\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y)\n",
    "\n",
    "y_train.value_counts() # Check on data balance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train data samples are not balanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    202\n",
       "0    202\n",
       "Name: Purchased, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, y_train = SMOTE().fit_resample(X_train, y_train)\n",
    "y_train.value_counts() # Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data for better processing in ML models\n",
    "scaler=StandardScaler()\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'LR':LogisticRegression(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'NB':GaussianNB(),\n",
    "    'SVM':SVC(),\n",
    "    'DT':DecisionTreeClassifier(),\n",
    "    'RF':RandomForestClassifier(),\n",
    "    'XGB':XGBClassifier()\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LR\n",
      "Training Accuracy: 0.8292079207920792\n",
      "Testing Accuracy: 0.83\n",
      "Confusion Matrix: [[43 12]\n",
      " [ 5 40]]\n",
      "Recall: 0.8888888888888888\n",
      "Precision: 0.7692307692307693\n",
      "F1 score: 0.8247422680412372\n",
      "FBeta score: 0.7905138339920948\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.78      0.83        55\n",
      "           1       0.77      0.89      0.82        45\n",
      "\n",
      "    accuracy                           0.83       100\n",
      "   macro avg       0.83      0.84      0.83       100\n",
      "weighted avg       0.84      0.83      0.83       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using KNN\n",
      "Training Accuracy: 0.943069306930693\n",
      "Testing Accuracy: 0.86\n",
      "Confusion Matrix: [[48  7]\n",
      " [ 7 38]]\n",
      "Recall: 0.8444444444444444\n",
      "Precision: 0.8444444444444444\n",
      "F1 score: 0.8444444444444444\n",
      "FBeta score: 0.8444444444444444\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.87      0.87        55\n",
      "           1       0.84      0.84      0.84        45\n",
      "\n",
      "    accuracy                           0.86       100\n",
      "   macro avg       0.86      0.86      0.86       100\n",
      "weighted avg       0.86      0.86      0.86       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using NB\n",
      "Training Accuracy: 0.9034653465346535\n",
      "Testing Accuracy: 0.87\n",
      "Confusion Matrix: [[46  9]\n",
      " [ 4 41]]\n",
      "Recall: 0.9111111111111111\n",
      "Precision: 0.82\n",
      "F1 score: 0.8631578947368421\n",
      "FBeta score: 0.836734693877551\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.92      0.84      0.88        55\n",
      "           1       0.82      0.91      0.86        45\n",
      "\n",
      "    accuracy                           0.87       100\n",
      "   macro avg       0.87      0.87      0.87       100\n",
      "weighted avg       0.88      0.87      0.87       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using SVM\n",
      "Training Accuracy: 0.9232673267326733\n",
      "Testing Accuracy: 0.9\n",
      "Confusion Matrix: [[48  7]\n",
      " [ 3 42]]\n",
      "Recall: 0.9333333333333333\n",
      "Precision: 0.8571428571428571\n",
      "F1 score: 0.8936170212765957\n",
      "FBeta score: 0.8713692946058091\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.94      0.87      0.91        55\n",
      "           1       0.86      0.93      0.89        45\n",
      "\n",
      "    accuracy                           0.90       100\n",
      "   macro avg       0.90      0.90      0.90       100\n",
      "weighted avg       0.90      0.90      0.90       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using DT\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.76\n",
      "Confusion Matrix: [[44 11]\n",
      " [13 32]]\n",
      "Recall: 0.7111111111111111\n",
      "Precision: 0.7441860465116279\n",
      "F1 score: 0.7272727272727273\n",
      "FBeta score: 0.7373271889400922\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.80      0.79        55\n",
      "           1       0.74      0.71      0.73        45\n",
      "\n",
      "    accuracy                           0.76       100\n",
      "   macro avg       0.76      0.76      0.76       100\n",
      "weighted avg       0.76      0.76      0.76       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using RF\n",
      "Training Accuracy: 1.0\n",
      "Testing Accuracy: 0.84\n",
      "Confusion Matrix: [[47  8]\n",
      " [ 8 37]]\n",
      "Recall: 0.8222222222222222\n",
      "Precision: 0.8222222222222222\n",
      "F1 score: 0.8222222222222222\n",
      "FBeta score: 0.8222222222222222\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85        55\n",
      "           1       0.82      0.82      0.82        45\n",
      "\n",
      "    accuracy                           0.84       100\n",
      "   macro avg       0.84      0.84      0.84       100\n",
      "weighted avg       0.84      0.84      0.84       100\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using XGB\n",
      "[23:05:47] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Training Accuracy: 0.9975247524752475\n",
      "Testing Accuracy: 0.81\n",
      "Confusion Matrix: [[47  8]\n",
      " [11 34]]\n",
      "Recall: 0.7555555555555555\n",
      "Precision: 0.8095238095238095\n",
      "F1 score: 0.7816091954022989\n",
      "FBeta score: 0.7981220657276996\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83        55\n",
      "           1       0.81      0.76      0.78        45\n",
      "\n",
      "    accuracy                           0.81       100\n",
      "   macro avg       0.81      0.81      0.81       100\n",
      "weighted avg       0.81      0.81      0.81       100\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shady\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f'Using {name}')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(f'Training Accuracy: {accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Testing Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "    print(f'F1 score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'FBeta score: {fbeta_score(y_test, y_pred, beta=0.5)}')\n",
    "    print(f'Classification Report: {classification_report(y_test, y_pred)}')\n",
    "    print('--'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Above results, it seems that **SVM** model has the highest accuracy with greater scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=SVC()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2) Titanic dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>435</th>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Carter, Miss. Lucile Polk</td>\n",
       "      <td>female</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>113760</td>\n",
       "      <td>120.00</td>\n",
       "      <td>B96 B98</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>873</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Carlsson, Mr. Frans Olof</td>\n",
       "      <td>male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>695</td>\n",
       "      <td>5.00</td>\n",
       "      <td>B51 B53 B55</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>809</th>\n",
       "      <td>810</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Chambers, Mrs. Norman Campbell (Bertha Griggs)</td>\n",
       "      <td>female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113806</td>\n",
       "      <td>53.10</td>\n",
       "      <td>E8</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>Williams, Mr. Charles Eugene</td>\n",
       "      <td>male</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>244373</td>\n",
       "      <td>13.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>453</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>Foreman, Mr. Benjamin Laventall</td>\n",
       "      <td>male</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>113051</td>\n",
       "      <td>27.75</td>\n",
       "      <td>C111</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PassengerId  Survived  Pclass  \\\n",
       "435          436         1       1   \n",
       "872          873         0       1   \n",
       "809          810         1       1   \n",
       "17            18         1       2   \n",
       "452          453         0       1   \n",
       "\n",
       "                                               Name     Sex   Age  SibSp  \\\n",
       "435                       Carter, Miss. Lucile Polk  female  14.0      1   \n",
       "872                        Carlsson, Mr. Frans Olof    male  33.0      0   \n",
       "809  Chambers, Mrs. Norman Campbell (Bertha Griggs)  female  33.0      1   \n",
       "17                     Williams, Mr. Charles Eugene    male   NaN      0   \n",
       "452                 Foreman, Mr. Benjamin Laventall    male  30.0      0   \n",
       "\n",
       "     Parch  Ticket    Fare        Cabin Embarked  \n",
       "435      2  113760  120.00      B96 B98        S  \n",
       "872      0     695    5.00  B51 B53 B55        S  \n",
       "809      0  113806   53.10           E8        S  \n",
       "17       0  244373   13.00          NaN        S  \n",
       "452      0  113051   27.75         C111        C  "
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tnc_df=pd.read_csv('Assignment Datasets/Titanic.csv')\n",
    "tnc_df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n"
     ]
    }
   ],
   "source": [
    "tnc_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NaNs\n",
    "tnc_df.Age.fillna(tnc_df.Age.mean(), inplace=True)\n",
    "imp=SimpleImputer(strategy='most_frequent')\n",
    "tnc_df.Embarked=imp.fit_transform(tnc_df[['Embarked']])\n",
    "\n",
    "# Classifying categorical data\n",
    "tnc_df=pd.get_dummies(tnc_df, columns=['Sex', 'Embarked'], drop_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    409\n",
       "1    259\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split on independent and dependent data\n",
    "X=tnc_df.drop(columns=['PassengerId', 'Survived', 'Name', 'Ticket', 'Cabin'])\n",
    "y=tnc_df.Survived\n",
    "\n",
    "# Split on Train and Test parts\n",
    "X_train, X_test, y_train, y_test=train_test_split(X, y)\n",
    "\n",
    "y_train.value_counts() # Check on data balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling data for better processing in ML models\n",
    "# [scaler] is defined above in Q1\n",
    "X_train=scaler.fit_transform(X_train)\n",
    "X_test=scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LR\n",
      "Training Accuracy: 0.7919161676646707\n",
      "Testing Accuracy: 0.8340807174887892\n",
      "Confusion Matrix: [[119  21]\n",
      " [ 16  67]]\n",
      "Recall: 0.8072289156626506\n",
      "Precision: 0.7613636363636364\n",
      "F1 score: 0.783625730994152\n",
      "FBeta score: 0.7701149425287356\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.85      0.87       140\n",
      "           1       0.76      0.81      0.78        83\n",
      "\n",
      "    accuracy                           0.83       223\n",
      "   macro avg       0.82      0.83      0.82       223\n",
      "weighted avg       0.84      0.83      0.83       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using KNN\n",
      "Training Accuracy: 0.8532934131736527\n",
      "Testing Accuracy: 0.852017937219731\n",
      "Confusion Matrix: [[121  19]\n",
      " [ 14  69]]\n",
      "Recall: 0.8313253012048193\n",
      "Precision: 0.7840909090909091\n",
      "F1 score: 0.8070175438596491\n",
      "FBeta score: 0.7931034482758621\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.90      0.86      0.88       140\n",
      "           1       0.78      0.83      0.81        83\n",
      "\n",
      "    accuracy                           0.85       223\n",
      "   macro avg       0.84      0.85      0.84       223\n",
      "weighted avg       0.85      0.85      0.85       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using NB\n",
      "Training Accuracy: 0.7844311377245509\n",
      "Testing Accuracy: 0.8026905829596412\n",
      "Confusion Matrix: [[113  27]\n",
      " [ 17  66]]\n",
      "Recall: 0.7951807228915663\n",
      "Precision: 0.7096774193548387\n",
      "F1 score: 0.7500000000000001\n",
      "FBeta score: 0.7252747252747254\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.81      0.84       140\n",
      "           1       0.71      0.80      0.75        83\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.79      0.80      0.79       223\n",
      "weighted avg       0.81      0.80      0.80       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using SVM\n",
      "Training Accuracy: 0.8353293413173652\n",
      "Testing Accuracy: 0.8475336322869955\n",
      "Confusion Matrix: [[124  16]\n",
      " [ 18  65]]\n",
      "Recall: 0.7831325301204819\n",
      "Precision: 0.8024691358024691\n",
      "F1 score: 0.7926829268292682\n",
      "FBeta score: 0.7985257985257985\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.87      0.89      0.88       140\n",
      "           1       0.80      0.78      0.79        83\n",
      "\n",
      "    accuracy                           0.85       223\n",
      "   macro avg       0.84      0.83      0.84       223\n",
      "weighted avg       0.85      0.85      0.85       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using DT\n",
      "Training Accuracy: 0.9865269461077845\n",
      "Testing Accuracy: 0.7757847533632287\n",
      "Confusion Matrix: [[107  33]\n",
      " [ 17  66]]\n",
      "Recall: 0.7951807228915663\n",
      "Precision: 0.6666666666666666\n",
      "F1 score: 0.7252747252747251\n",
      "FBeta score: 0.6889352818371607\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.76      0.81       140\n",
      "           1       0.67      0.80      0.73        83\n",
      "\n",
      "    accuracy                           0.78       223\n",
      "   macro avg       0.76      0.78      0.77       223\n",
      "weighted avg       0.79      0.78      0.78       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using RF\n",
      "Training Accuracy: 0.9865269461077845\n",
      "Testing Accuracy: 0.8071748878923767\n",
      "Confusion Matrix: [[117  23]\n",
      " [ 20  63]]\n",
      "Recall: 0.7590361445783133\n",
      "Precision: 0.7325581395348837\n",
      "F1 score: 0.7455621301775147\n",
      "FBeta score: 0.7377049180327869\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.84      0.84       140\n",
      "           1       0.73      0.76      0.75        83\n",
      "\n",
      "    accuracy                           0.81       223\n",
      "   macro avg       0.79      0.80      0.80       223\n",
      "weighted avg       0.81      0.81      0.81       223\n",
      "\n",
      "------------------------------------------------------------\n",
      "Using XGB\n",
      "[23:05:44] WARNING: ..\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Shady\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy: 0.9760479041916168\n",
      "Testing Accuracy: 0.8026905829596412\n",
      "Confusion Matrix: [[118  22]\n",
      " [ 22  61]]\n",
      "Recall: 0.7349397590361446\n",
      "Precision: 0.7349397590361446\n",
      "F1 score: 0.7349397590361445\n",
      "FBeta score: 0.7349397590361446\n",
      "Classification Report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.84      0.84       140\n",
      "           1       0.73      0.73      0.73        83\n",
      "\n",
      "    accuracy                           0.80       223\n",
      "   macro avg       0.79      0.79      0.79       223\n",
      "weighted avg       0.80      0.80      0.80       223\n",
      "\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# [models] is defined above in Q1\n",
    "for name, model in models.items():\n",
    "    print(f'Using {name}')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred=model.predict(X_test)\n",
    "    print(f'Training Accuracy: {accuracy_score(y_train, model.predict(X_train))}')\n",
    "    print(f'Testing Accuracy: {accuracy_score(y_test, y_pred)}')\n",
    "    print(f'Confusion Matrix: {confusion_matrix(y_test, y_pred)}')\n",
    "    print(f'Recall: {recall_score(y_test, y_pred)}')\n",
    "    print(f'Precision: {precision_score(y_test, y_pred)}')\n",
    "    print(f'F1 score: {f1_score(y_test, y_pred)}')\n",
    "    print(f'FBeta score: {fbeta_score(y_test, y_pred, beta=0.5)}')\n",
    "    print(f'Classification Report: {classification_report(y_test, y_pred)}')\n",
    "    print('--'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Above results, it seems that **KNN** model has the highest accuracy with greater scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "model=KNeighborsClassifier()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred=model.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Cross Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using LR\n",
      "['test_score', 'train_score']\n",
      "[0.7946142451176007, 0.8026930597526599]\n",
      "------------------------------------------------------------\n",
      "Using KNN\n",
      "['test_score', 'train_score']\n",
      "[0.694789588245964, 0.8033690303872381]\n",
      "------------------------------------------------------------\n",
      "Using NB\n",
      "['test_score', 'train_score']\n",
      "[0.7856581413628394, 0.7950608796808548]\n",
      "------------------------------------------------------------\n",
      "Using SVM\n",
      "['test_score', 'train_score']\n",
      "[0.6734460971038153, 0.6803641413903229]\n",
      "------------------------------------------------------------\n",
      "Using DT\n",
      "['test_score', 'train_score']\n",
      "[0.7789542898603301, 0.9840635992836405]\n",
      "------------------------------------------------------------\n",
      "Using RF\n",
      "['test_score', 'train_score']\n",
      "[0.8148316101336235, 0.9840635992836405]\n",
      "------------------------------------------------------------\n",
      "Using XGB\n",
      "['test_score', 'train_score']\n",
      "[0.8092463268637765, 0.9699232368231073]\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name, model in models.items():\n",
    "    print(f'Using {name}')\n",
    "    scores=cross_validate(model, X, y, cv=6, n_jobs=-1, return_train_score=True)\n",
    "    print(\"['test_score', 'train_score']\")\n",
    "    print([scores.get(scoring).mean() for scoring in ['test_score', 'train_score']])\n",
    "    print('--'*30)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Above results, it seems that **Random Forest Classifier** model has the highest accuracy score."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
