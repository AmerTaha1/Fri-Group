{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "48a29b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b51b9e30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>Vanuatu</td>\n",
       "      <td>29.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>5.25</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2950</td>\n",
       "      <td>2.62</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>Venezuela</td>\n",
       "      <td>17.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.91</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16500</td>\n",
       "      <td>45.90</td>\n",
       "      <td>75.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>Vietnam</td>\n",
       "      <td>23.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>80.2</td>\n",
       "      <td>4490</td>\n",
       "      <td>12.10</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>Yemen</td>\n",
       "      <td>56.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.18</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4480</td>\n",
       "      <td>23.60</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>Zambia</td>\n",
       "      <td>83.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3280</td>\n",
       "      <td>14.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 country  child_mort  exports  health  imports  income  \\\n",
       "0            Afghanistan        90.2     10.0    7.58     44.9    1610   \n",
       "1                Albania        16.6     28.0    6.55     48.6    9930   \n",
       "2                Algeria        27.3     38.4    4.17     31.4   12900   \n",
       "3                 Angola       119.0     62.3    2.85     42.9    5900   \n",
       "4    Antigua and Barbuda        10.3     45.5    6.03     58.9   19100   \n",
       "..                   ...         ...      ...     ...      ...     ...   \n",
       "162              Vanuatu        29.2     46.6    5.25     52.7    2950   \n",
       "163            Venezuela        17.1     28.5    4.91     17.6   16500   \n",
       "164              Vietnam        23.3     72.0    6.84     80.2    4490   \n",
       "165                Yemen        56.3     30.0    5.18     34.4    4480   \n",
       "166               Zambia        83.1     37.0    5.89     30.9    3280   \n",
       "\n",
       "     inflation  life_expec  total_fer   gdpp  \n",
       "0         9.44        56.2       5.82    553  \n",
       "1         4.49        76.3       1.65   4090  \n",
       "2        16.10        76.5       2.89   4460  \n",
       "3        22.40        60.1       6.16   3530  \n",
       "4         1.44        76.8       2.13  12200  \n",
       "..         ...         ...        ...    ...  \n",
       "162       2.62        63.0       3.50   2970  \n",
       "163      45.90        75.4       2.47  13500  \n",
       "164      12.10        73.1       1.95   1310  \n",
       "165      23.60        67.5       4.67   1310  \n",
       "166      14.00        52.0       5.40   1460  \n",
       "\n",
       "[167 rows x 10 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('Country-data.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0814acfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country       0\n",
       "child_mort    0\n",
       "exports       0\n",
       "health        0\n",
       "imports       0\n",
       "income        0\n",
       "inflation     0\n",
       "life_expec    0\n",
       "total_fer     0\n",
       "gdpp          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8bd91688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>29.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>5.25</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2950</td>\n",
       "      <td>2.62</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>17.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.91</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16500</td>\n",
       "      <td>45.90</td>\n",
       "      <td>75.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>23.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>80.2</td>\n",
       "      <td>4490</td>\n",
       "      <td>12.10</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>56.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.18</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4480</td>\n",
       "      <td>23.60</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>83.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3280</td>\n",
       "      <td>14.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     child_mort  exports  health  imports  income  inflation  life_expec  \\\n",
       "0          90.2     10.0    7.58     44.9    1610       9.44        56.2   \n",
       "1          16.6     28.0    6.55     48.6    9930       4.49        76.3   \n",
       "2          27.3     38.4    4.17     31.4   12900      16.10        76.5   \n",
       "3         119.0     62.3    2.85     42.9    5900      22.40        60.1   \n",
       "4          10.3     45.5    6.03     58.9   19100       1.44        76.8   \n",
       "..          ...      ...     ...      ...     ...        ...         ...   \n",
       "162        29.2     46.6    5.25     52.7    2950       2.62        63.0   \n",
       "163        17.1     28.5    4.91     17.6   16500      45.90        75.4   \n",
       "164        23.3     72.0    6.84     80.2    4490      12.10        73.1   \n",
       "165        56.3     30.0    5.18     34.4    4480      23.60        67.5   \n",
       "166        83.1     37.0    5.89     30.9    3280      14.00        52.0   \n",
       "\n",
       "     total_fer   gdpp  \n",
       "0         5.82    553  \n",
       "1         1.65   4090  \n",
       "2         2.89   4460  \n",
       "3         6.16   3530  \n",
       "4         2.13  12200  \n",
       "..         ...    ...  \n",
       "162       3.50   2970  \n",
       "163       2.47  13500  \n",
       "164       1.95   1310  \n",
       "165       4.67   1310  \n",
       "166       5.40   1460  \n",
       "\n",
       "[167 rows x 9 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=df.drop('country',axis=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "70b734ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.29153238, -1.13827979,  0.27908825, ..., -1.61909203,\n",
       "         1.90288227, -0.67917961],\n",
       "       [-0.5389489 , -0.47965843, -0.09701618, ...,  0.64786643,\n",
       "        -0.85997281, -0.48562324],\n",
       "       [-0.27283273, -0.09912164, -0.96607302, ...,  0.67042323,\n",
       "        -0.0384044 , -0.46537561],\n",
       "       ...,\n",
       "       [-0.37231541,  1.13030491,  0.0088773 , ...,  0.28695762,\n",
       "        -0.66120626, -0.63775406],\n",
       "       [ 0.44841668, -0.40647827, -0.59727159, ..., -0.34463279,\n",
       "         1.14094382, -0.63775406],\n",
       "       [ 1.11495062, -0.15034774, -0.33801514, ..., -2.09278484,\n",
       "         1.6246091 , -0.62954556]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x=scaler.fit_transform(df)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "7834169a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "dendogram=sch.dendrogram(sch.linkage(x,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "a18b6260",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.440</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.490</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.100</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.400</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.440</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>14.5</td>\n",
       "      <td>18.9</td>\n",
       "      <td>8.10</td>\n",
       "      <td>16.0</td>\n",
       "      <td>18700</td>\n",
       "      <td>20.900</td>\n",
       "      <td>75.8</td>\n",
       "      <td>2.37</td>\n",
       "      <td>10300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>18.1</td>\n",
       "      <td>20.8</td>\n",
       "      <td>4.40</td>\n",
       "      <td>45.3</td>\n",
       "      <td>6700</td>\n",
       "      <td>7.770</td>\n",
       "      <td>73.3</td>\n",
       "      <td>1.69</td>\n",
       "      <td>3220</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>4.8</td>\n",
       "      <td>19.8</td>\n",
       "      <td>8.73</td>\n",
       "      <td>20.9</td>\n",
       "      <td>41400</td>\n",
       "      <td>1.160</td>\n",
       "      <td>82.0</td>\n",
       "      <td>1.93</td>\n",
       "      <td>51900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>4.3</td>\n",
       "      <td>51.3</td>\n",
       "      <td>11.00</td>\n",
       "      <td>47.8</td>\n",
       "      <td>43200</td>\n",
       "      <td>0.873</td>\n",
       "      <td>80.5</td>\n",
       "      <td>1.44</td>\n",
       "      <td>46900</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>39.2</td>\n",
       "      <td>54.3</td>\n",
       "      <td>5.88</td>\n",
       "      <td>20.7</td>\n",
       "      <td>16000</td>\n",
       "      <td>13.800</td>\n",
       "      <td>69.1</td>\n",
       "      <td>1.92</td>\n",
       "      <td>5840</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>13.8</td>\n",
       "      <td>35.0</td>\n",
       "      <td>7.89</td>\n",
       "      <td>43.7</td>\n",
       "      <td>22900</td>\n",
       "      <td>-0.393</td>\n",
       "      <td>73.8</td>\n",
       "      <td>1.86</td>\n",
       "      <td>28000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>8.6</td>\n",
       "      <td>69.5</td>\n",
       "      <td>4.97</td>\n",
       "      <td>50.9</td>\n",
       "      <td>41100</td>\n",
       "      <td>7.440</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2.16</td>\n",
       "      <td>20700</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>49.4</td>\n",
       "      <td>16.0</td>\n",
       "      <td>3.52</td>\n",
       "      <td>21.8</td>\n",
       "      <td>2440</td>\n",
       "      <td>7.140</td>\n",
       "      <td>70.4</td>\n",
       "      <td>2.33</td>\n",
       "      <td>758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.2</td>\n",
       "      <td>39.5</td>\n",
       "      <td>7.97</td>\n",
       "      <td>48.7</td>\n",
       "      <td>15300</td>\n",
       "      <td>0.321</td>\n",
       "      <td>76.7</td>\n",
       "      <td>1.78</td>\n",
       "      <td>16000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>5.5</td>\n",
       "      <td>51.4</td>\n",
       "      <td>5.61</td>\n",
       "      <td>64.5</td>\n",
       "      <td>16200</td>\n",
       "      <td>15.100</td>\n",
       "      <td>70.4</td>\n",
       "      <td>1.49</td>\n",
       "      <td>6030</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>4.5</td>\n",
       "      <td>76.4</td>\n",
       "      <td>10.70</td>\n",
       "      <td>74.7</td>\n",
       "      <td>41100</td>\n",
       "      <td>1.880</td>\n",
       "      <td>80.0</td>\n",
       "      <td>1.86</td>\n",
       "      <td>44400</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>18.8</td>\n",
       "      <td>58.2</td>\n",
       "      <td>5.20</td>\n",
       "      <td>57.5</td>\n",
       "      <td>7880</td>\n",
       "      <td>1.140</td>\n",
       "      <td>71.4</td>\n",
       "      <td>2.71</td>\n",
       "      <td>4340</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>111.0</td>\n",
       "      <td>23.8</td>\n",
       "      <td>4.10</td>\n",
       "      <td>37.2</td>\n",
       "      <td>1820</td>\n",
       "      <td>0.885</td>\n",
       "      <td>61.8</td>\n",
       "      <td>5.36</td>\n",
       "      <td>758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>42.7</td>\n",
       "      <td>42.5</td>\n",
       "      <td>5.20</td>\n",
       "      <td>70.7</td>\n",
       "      <td>6420</td>\n",
       "      <td>5.990</td>\n",
       "      <td>72.1</td>\n",
       "      <td>2.38</td>\n",
       "      <td>2180</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>46.6</td>\n",
       "      <td>41.2</td>\n",
       "      <td>4.84</td>\n",
       "      <td>34.3</td>\n",
       "      <td>5410</td>\n",
       "      <td>8.780</td>\n",
       "      <td>71.6</td>\n",
       "      <td>3.20</td>\n",
       "      <td>1980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    child_mort  exports  health  imports  income  inflation  life_expec  \\\n",
       "0         90.2     10.0    7.58     44.9    1610      9.440        56.2   \n",
       "1         16.6     28.0    6.55     48.6    9930      4.490        76.3   \n",
       "2         27.3     38.4    4.17     31.4   12900     16.100        76.5   \n",
       "3        119.0     62.3    2.85     42.9    5900     22.400        60.1   \n",
       "4         10.3     45.5    6.03     58.9   19100      1.440        76.8   \n",
       "5         14.5     18.9    8.10     16.0   18700     20.900        75.8   \n",
       "6         18.1     20.8    4.40     45.3    6700      7.770        73.3   \n",
       "7          4.8     19.8    8.73     20.9   41400      1.160        82.0   \n",
       "8          4.3     51.3   11.00     47.8   43200      0.873        80.5   \n",
       "9         39.2     54.3    5.88     20.7   16000     13.800        69.1   \n",
       "10        13.8     35.0    7.89     43.7   22900     -0.393        73.8   \n",
       "11         8.6     69.5    4.97     50.9   41100      7.440        76.0   \n",
       "12        49.4     16.0    3.52     21.8    2440      7.140        70.4   \n",
       "13        14.2     39.5    7.97     48.7   15300      0.321        76.7   \n",
       "14         5.5     51.4    5.61     64.5   16200     15.100        70.4   \n",
       "15         4.5     76.4   10.70     74.7   41100      1.880        80.0   \n",
       "16        18.8     58.2    5.20     57.5    7880      1.140        71.4   \n",
       "17       111.0     23.8    4.10     37.2    1820      0.885        61.8   \n",
       "18        42.7     42.5    5.20     70.7    6420      5.990        72.1   \n",
       "19        46.6     41.2    4.84     34.3    5410      8.780        71.6   \n",
       "\n",
       "    total_fer   gdpp  clusters  \n",
       "0        5.82    553         0  \n",
       "1        1.65   4090         0  \n",
       "2        2.89   4460         0  \n",
       "3        6.16   3530         0  \n",
       "4        2.13  12200         0  \n",
       "5        2.37  10300         0  \n",
       "6        1.69   3220         0  \n",
       "7        1.93  51900         1  \n",
       "8        1.44  46900         1  \n",
       "9        1.92   5840         0  \n",
       "10       1.86  28000         0  \n",
       "11       2.16  20700         0  \n",
       "12       2.33    758         0  \n",
       "13       1.78  16000         0  \n",
       "14       1.49   6030         0  \n",
       "15       1.86  44400         1  \n",
       "16       2.71   4340         0  \n",
       "17       5.36    758         0  \n",
       "18       2.38   2180         0  \n",
       "19       3.20   1980         0  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model=AgglomerativeClustering(n_clusters=2)\n",
    "clusters=model.fit_predict(x)\n",
    "df['clusters']=clusters\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "f1c49632",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>29.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>5.25</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2950</td>\n",
       "      <td>2.62</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2970</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>17.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.91</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16500</td>\n",
       "      <td>45.90</td>\n",
       "      <td>75.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>23.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>80.2</td>\n",
       "      <td>4490</td>\n",
       "      <td>12.10</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>56.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.18</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4480</td>\n",
       "      <td>23.60</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>83.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3280</td>\n",
       "      <td>14.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1460</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     child_mort  exports  health  imports  income  inflation  life_expec  \\\n",
       "0          90.2     10.0    7.58     44.9    1610       9.44        56.2   \n",
       "1          16.6     28.0    6.55     48.6    9930       4.49        76.3   \n",
       "2          27.3     38.4    4.17     31.4   12900      16.10        76.5   \n",
       "3         119.0     62.3    2.85     42.9    5900      22.40        60.1   \n",
       "4          10.3     45.5    6.03     58.9   19100       1.44        76.8   \n",
       "..          ...      ...     ...      ...     ...        ...         ...   \n",
       "162        29.2     46.6    5.25     52.7    2950       2.62        63.0   \n",
       "163        17.1     28.5    4.91     17.6   16500      45.90        75.4   \n",
       "164        23.3     72.0    6.84     80.2    4490      12.10        73.1   \n",
       "165        56.3     30.0    5.18     34.4    4480      23.60        67.5   \n",
       "166        83.1     37.0    5.89     30.9    3280      14.00        52.0   \n",
       "\n",
       "     total_fer   gdpp  \n",
       "0         5.82    553  \n",
       "1         1.65   4090  \n",
       "2         2.89   4460  \n",
       "3         6.16   3530  \n",
       "4         2.13  12200  \n",
       "..         ...    ...  \n",
       "162       3.50   2970  \n",
       "163       2.47  13500  \n",
       "164       1.95   1310  \n",
       "165       4.67   1310  \n",
       "166       5.40   1460  \n",
       "\n",
       "[167 rows x 9 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=df.drop('clusters',axis=1)\n",
    "y=df['clusters']\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ce0ce25b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ef65e930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113\n",
       "1     20\n",
       "Name: clusters, dtype: int64"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c7cfd98c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "smoter=SMOTE()\n",
    "x_train,y_train=smoter.fit_resample(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "70dcecea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    113\n",
       "1    113\n",
       "Name: clusters, dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "f0dc5825",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "8b851580",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,fbeta_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "69621c5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'LR':LogisticRegression(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'DT':DecisionTreeClassifier(),\n",
    "    'RF':RandomForestClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'XG':XGBClassifier(),\n",
    "    'G':GaussianNB()\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "ca919621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:LR\n",
      "train accurancy:0.995575221238938\n",
      "test accurancy:0.9705882352941176\n",
      "test con:[[29  1]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:0.8\n",
      "f1:0.888888888888889\n",
      " fbeta :0.8333333333333334\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.97      0.98        30\n",
      "           1       0.80      1.00      0.89         4\n",
      "\n",
      "    accuracy                           0.97        34\n",
      "   macro avg       0.90      0.98      0.94        34\n",
      "weighted avg       0.98      0.97      0.97        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:KNN\n",
      "train accurancy:0.9823008849557522\n",
      "test accurancy:0.9411764705882353\n",
      "test con:[[28  2]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:0.6666666666666666\n",
      "f1:0.8\n",
      " fbeta :0.7142857142857142\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.83      0.97      0.88        34\n",
      "weighted avg       0.96      0.94      0.95        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:DT\n",
      "train accurancy:1.0\n",
      "test accurancy:1.0\n",
      "test con:[[30  0]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:1.0\n",
      "f1:1.0\n",
      " fbeta :1.0\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:RF\n",
      "train accurancy:1.0\n",
      "test accurancy:1.0\n",
      "test con:[[30  0]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:1.0\n",
      "f1:1.0\n",
      " fbeta :1.0\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:SVC\n",
      "train accurancy:0.9911504424778761\n",
      "test accurancy:0.9411764705882353\n",
      "test con:[[28  2]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:0.6666666666666666\n",
      "f1:0.8\n",
      " fbeta :0.7142857142857142\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.83      0.97      0.88        34\n",
      "weighted avg       0.96      0.94      0.95        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:XG\n",
      "[11:52:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "train accurancy:1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test accurancy:1.0\n",
      "test con:[[30  0]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:1.0\n",
      "f1:1.0\n",
      " fbeta :1.0\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        30\n",
      "           1       1.00      1.00      1.00         4\n",
      "\n",
      "    accuracy                           1.00        34\n",
      "   macro avg       1.00      1.00      1.00        34\n",
      "weighted avg       1.00      1.00      1.00        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:G\n",
      "train accurancy:0.9690265486725663\n",
      "test accurancy:0.9411764705882353\n",
      "test con:[[28  2]\n",
      " [ 0  4]]\n",
      "recall:1.0\n",
      " pre:0.6666666666666666\n",
      "f1:0.8\n",
      " fbeta :0.7142857142857142\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.93      0.97        30\n",
      "           1       0.67      1.00      0.80         4\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.83      0.97      0.88        34\n",
      "weighted avg       0.96      0.94      0.95        34\n",
      "\n",
      "--------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "    print(f'using:{name}')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_predict=model.predict(x_test)\n",
    "    print(f'train accurancy:{accuracy_score(y_train,model.predict(x_train))}')\n",
    "    print(f'test accurancy:{accuracy_score(y_test,y_predict)}')\n",
    "    print(f'test con:{confusion_matrix(y_test,y_predict)}')\n",
    "    print(f'recall:{recall_score(y_test,y_predict)}')\n",
    "    print(f' pre:{precision_score(y_test,y_predict)}')\n",
    "    print(f'f1:{f1_score(y_test,y_predict)}')\n",
    "    print(f' fbeta :{fbeta_score(y_test,y_predict,beta=.5)}')\n",
    "    print(f' report :{classification_report(y_test,y_predict)}')\n",
    "\n",
    "    print('-'*33,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "02859222",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1c8649c2670>]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "wcss=[]\n",
    "for i in range(1,80):\n",
    "    model=KMeans(n_clusters=i)\n",
    "    clusters=model.fit_predict(x)\n",
    "    wcss.append(model.inertia_)\n",
    "plt.plot(range(1,80),wcss)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "cd655d0b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "      <th>clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>29.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>5.25</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2950</td>\n",
       "      <td>2.62</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>17.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.91</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16500</td>\n",
       "      <td>45.90</td>\n",
       "      <td>75.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13500</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>23.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>80.2</td>\n",
       "      <td>4490</td>\n",
       "      <td>12.10</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>56.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.18</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4480</td>\n",
       "      <td>23.60</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1310</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>83.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3280</td>\n",
       "      <td>14.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1460</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     child_mort  exports  health  imports  income  inflation  life_expec  \\\n",
       "0          90.2     10.0    7.58     44.9    1610       9.44        56.2   \n",
       "1          16.6     28.0    6.55     48.6    9930       4.49        76.3   \n",
       "2          27.3     38.4    4.17     31.4   12900      16.10        76.5   \n",
       "3         119.0     62.3    2.85     42.9    5900      22.40        60.1   \n",
       "4          10.3     45.5    6.03     58.9   19100       1.44        76.8   \n",
       "..          ...      ...     ...      ...     ...        ...         ...   \n",
       "162        29.2     46.6    5.25     52.7    2950       2.62        63.0   \n",
       "163        17.1     28.5    4.91     17.6   16500      45.90        75.4   \n",
       "164        23.3     72.0    6.84     80.2    4490      12.10        73.1   \n",
       "165        56.3     30.0    5.18     34.4    4480      23.60        67.5   \n",
       "166        83.1     37.0    5.89     30.9    3280      14.00        52.0   \n",
       "\n",
       "     total_fer   gdpp  clusters  \n",
       "0         5.82    553         0  \n",
       "1         1.65   4090         0  \n",
       "2         2.89   4460         2  \n",
       "3         6.16   3530         0  \n",
       "4         2.13  12200         2  \n",
       "..         ...    ...       ...  \n",
       "162       3.50   2970         0  \n",
       "163       2.47  13500         2  \n",
       "164       1.95   1310         0  \n",
       "165       4.67   1310         0  \n",
       "166       5.40   1460         0  \n",
       "\n",
       "[167 rows x 10 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KMeans(n_clusters=5)\n",
    "clusters=model.fit_predict(x)\n",
    "df['clusters']=clusters\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "326f552a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop('clusters',axis=1)\n",
    "y=df['clusters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "40063a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "1892edc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "scaler.fit(x_train)\n",
    "x_train=scaler.transform(x_train)\n",
    "x_test=scaler.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "47954f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,fbeta_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "bb587b98",
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'LR':LogisticRegression(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'DT':DecisionTreeClassifier(),\n",
    "    'RF':RandomForestClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'XG':XGBClassifier(),\n",
    "    'G':GaussianNB()\n",
    "    \n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "9053cfe1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:LR\n",
      "train accurancy:0.9398496240601504\n",
      "test accurancy:0.7941176470588235\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88        16\n",
      "           1       0.67      1.00      0.80         4\n",
      "           2       0.80      0.73      0.76        11\n",
      "           4       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.57      0.67      0.61        34\n",
      "weighted avg       0.73      0.79      0.76        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:KNN\n",
      "train accurancy:0.8721804511278195\n",
      "test accurancy:0.7941176470588235\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.88      0.82        16\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.78      0.64      0.70        11\n",
      "           4       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.84      0.79      0.80        34\n",
      "weighted avg       0.80      0.79      0.79        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:DT\n",
      "train accurancy:1.0\n",
      "test accurancy:0.9411764705882353\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.67      1.00      0.80         4\n",
      "           2       1.00      1.00      1.00        11\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.92      0.83      0.82        34\n",
      "weighted avg       0.96      0.94      0.93        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:RF\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accurancy:1.0\n",
      "test accurancy:0.9411764705882353\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.67      1.00      0.80         4\n",
      "           2       1.00      1.00      1.00        11\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.92      0.83      0.82        34\n",
      "weighted avg       0.96      0.94      0.93        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:SVC\n",
      "train accurancy:0.9398496240601504\n",
      "test accurancy:0.8529411764705882\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.83      0.94      0.88        16\n",
      "           1       0.80      1.00      0.89         4\n",
      "           2       0.89      0.73      0.80        11\n",
      "           4       1.00      0.67      0.80         3\n",
      "\n",
      "    accuracy                           0.85        34\n",
      "   macro avg       0.88      0.83      0.84        34\n",
      "weighted avg       0.86      0.85      0.85        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:XG\n",
      "[11:55:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train accurancy:1.0\n",
      "test accurancy:0.9411764705882353\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        16\n",
      "           1       0.67      1.00      0.80         4\n",
      "           2       1.00      1.00      1.00        11\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.94        34\n",
      "   macro avg       0.92      0.83      0.82        34\n",
      "weighted avg       0.96      0.94      0.93        34\n",
      "\n",
      "--------------------------------- \n",
      "\n",
      "using:G\n",
      "train accurancy:0.9097744360902256\n",
      "test accurancy:0.7941176470588235\n",
      " report :              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.69      0.81        16\n",
      "           1       0.67      1.00      0.80         4\n",
      "           2       0.69      1.00      0.81        11\n",
      "           4       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.79        34\n",
      "   macro avg       0.84      0.76      0.73        34\n",
      "weighted avg       0.86      0.79      0.79        34\n",
      "\n",
      "--------------------------------- \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for name,model in models.items():\n",
    "    print(f'using:{name}')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_predict=model.predict(x_test)\n",
    "    print(f'train accurancy:{accuracy_score(y_train,model.predict(x_train))}')\n",
    "    print(f'test accurancy:{accuracy_score(y_test,y_predict)}')\n",
    "    print(f' report :{classification_report(y_test,y_predict)}')\n",
    "\n",
    "    print('-'*33,'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec04019e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
