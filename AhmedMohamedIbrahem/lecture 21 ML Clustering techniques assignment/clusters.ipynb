{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/Country-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>country</th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Afghanistan</td>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Albania</td>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Algeria</td>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Angola</td>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Antigua and Barbuda</td>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               country  child_mort  exports  health  imports  income  \\\n",
       "0          Afghanistan        90.2     10.0    7.58     44.9    1610   \n",
       "1              Albania        16.6     28.0    6.55     48.6    9930   \n",
       "2              Algeria        27.3     38.4    4.17     31.4   12900   \n",
       "3               Angola       119.0     62.3    2.85     42.9    5900   \n",
       "4  Antigua and Barbuda        10.3     45.5    6.03     58.9   19100   \n",
       "\n",
       "   inflation  life_expec  total_fer   gdpp  \n",
       "0       9.44        56.2       5.82    553  \n",
       "1       4.49        76.3       1.65   4090  \n",
       "2      16.10        76.5       2.89   4460  \n",
       "3      22.40        60.1       6.16   3530  \n",
       "4       1.44        76.8       2.13  12200  "
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "country       0\n",
       "child_mort    0\n",
       "exports       0\n",
       "health        0\n",
       "imports       0\n",
       "income        0\n",
       "inflation     0\n",
       "life_expec    0\n",
       "total_fer     0\n",
       "gdpp          0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 167 entries, 0 to 166\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count  Dtype  \n",
      "---  ------      --------------  -----  \n",
      " 0   country     167 non-null    object \n",
      " 1   child_mort  167 non-null    float64\n",
      " 2   exports     167 non-null    float64\n",
      " 3   health      167 non-null    float64\n",
      " 4   imports     167 non-null    float64\n",
      " 5   income      167 non-null    int64  \n",
      " 6   inflation   167 non-null    float64\n",
      " 7   life_expec  167 non-null    float64\n",
      " 8   total_fer   167 non-null    float64\n",
      " 9   gdpp        167 non-null    int64  \n",
      "dtypes: float64(7), int64(2), object(1)\n",
      "memory usage: 13.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('country',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x=scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Elbow Method')"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "wcss=[]\n",
    "for i in range(1,11):\n",
    "    model=KMeans(n_clusters=i)\n",
    "    clusters=model.fit_predict(x)\n",
    "    wcss.append(model.inertia_)\n",
    "    \n",
    "plt.plot(range(1,11),wcss)\n",
    "plt.xlabel('n_clusters')\n",
    "plt.ylabel('WCSS')\n",
    "plt.title('Elbow Method')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>child_mort</th>\n",
       "      <th>exports</th>\n",
       "      <th>health</th>\n",
       "      <th>imports</th>\n",
       "      <th>income</th>\n",
       "      <th>inflation</th>\n",
       "      <th>life_expec</th>\n",
       "      <th>total_fer</th>\n",
       "      <th>gdpp</th>\n",
       "      <th>Clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>90.2</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.58</td>\n",
       "      <td>44.9</td>\n",
       "      <td>1610</td>\n",
       "      <td>9.44</td>\n",
       "      <td>56.2</td>\n",
       "      <td>5.82</td>\n",
       "      <td>553</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>16.6</td>\n",
       "      <td>28.0</td>\n",
       "      <td>6.55</td>\n",
       "      <td>48.6</td>\n",
       "      <td>9930</td>\n",
       "      <td>4.49</td>\n",
       "      <td>76.3</td>\n",
       "      <td>1.65</td>\n",
       "      <td>4090</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.3</td>\n",
       "      <td>38.4</td>\n",
       "      <td>4.17</td>\n",
       "      <td>31.4</td>\n",
       "      <td>12900</td>\n",
       "      <td>16.10</td>\n",
       "      <td>76.5</td>\n",
       "      <td>2.89</td>\n",
       "      <td>4460</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>119.0</td>\n",
       "      <td>62.3</td>\n",
       "      <td>2.85</td>\n",
       "      <td>42.9</td>\n",
       "      <td>5900</td>\n",
       "      <td>22.40</td>\n",
       "      <td>60.1</td>\n",
       "      <td>6.16</td>\n",
       "      <td>3530</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10.3</td>\n",
       "      <td>45.5</td>\n",
       "      <td>6.03</td>\n",
       "      <td>58.9</td>\n",
       "      <td>19100</td>\n",
       "      <td>1.44</td>\n",
       "      <td>76.8</td>\n",
       "      <td>2.13</td>\n",
       "      <td>12200</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>29.2</td>\n",
       "      <td>46.6</td>\n",
       "      <td>5.25</td>\n",
       "      <td>52.7</td>\n",
       "      <td>2950</td>\n",
       "      <td>2.62</td>\n",
       "      <td>63.0</td>\n",
       "      <td>3.50</td>\n",
       "      <td>2970</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>163</th>\n",
       "      <td>17.1</td>\n",
       "      <td>28.5</td>\n",
       "      <td>4.91</td>\n",
       "      <td>17.6</td>\n",
       "      <td>16500</td>\n",
       "      <td>45.90</td>\n",
       "      <td>75.4</td>\n",
       "      <td>2.47</td>\n",
       "      <td>13500</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>164</th>\n",
       "      <td>23.3</td>\n",
       "      <td>72.0</td>\n",
       "      <td>6.84</td>\n",
       "      <td>80.2</td>\n",
       "      <td>4490</td>\n",
       "      <td>12.10</td>\n",
       "      <td>73.1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1310</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>56.3</td>\n",
       "      <td>30.0</td>\n",
       "      <td>5.18</td>\n",
       "      <td>34.4</td>\n",
       "      <td>4480</td>\n",
       "      <td>23.60</td>\n",
       "      <td>67.5</td>\n",
       "      <td>4.67</td>\n",
       "      <td>1310</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>83.1</td>\n",
       "      <td>37.0</td>\n",
       "      <td>5.89</td>\n",
       "      <td>30.9</td>\n",
       "      <td>3280</td>\n",
       "      <td>14.00</td>\n",
       "      <td>52.0</td>\n",
       "      <td>5.40</td>\n",
       "      <td>1460</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>167 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     child_mort  exports  health  imports  income  inflation  life_expec  \\\n",
       "0          90.2     10.0    7.58     44.9    1610       9.44        56.2   \n",
       "1          16.6     28.0    6.55     48.6    9930       4.49        76.3   \n",
       "2          27.3     38.4    4.17     31.4   12900      16.10        76.5   \n",
       "3         119.0     62.3    2.85     42.9    5900      22.40        60.1   \n",
       "4          10.3     45.5    6.03     58.9   19100       1.44        76.8   \n",
       "..          ...      ...     ...      ...     ...        ...         ...   \n",
       "162        29.2     46.6    5.25     52.7    2950       2.62        63.0   \n",
       "163        17.1     28.5    4.91     17.6   16500      45.90        75.4   \n",
       "164        23.3     72.0    6.84     80.2    4490      12.10        73.1   \n",
       "165        56.3     30.0    5.18     34.4    4480      23.60        67.5   \n",
       "166        83.1     37.0    5.89     30.9    3280      14.00        52.0   \n",
       "\n",
       "     total_fer   gdpp  Clusters  \n",
       "0         5.82    553         1  \n",
       "1         1.65   4090         2  \n",
       "2         2.89   4460         7  \n",
       "3         6.16   3530         1  \n",
       "4         2.13  12200         2  \n",
       "..         ...    ...       ...  \n",
       "162       3.50   2970         0  \n",
       "163       2.47  13500         7  \n",
       "164       1.95   1310         2  \n",
       "165       4.67   1310         7  \n",
       "166       5.40   1460         1  \n",
       "\n",
       "[167 rows x 10 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model=KMeans(n_clusters=8)\n",
    "clusters=model.fit_predict(x)\n",
    "df['Clusters']=clusters\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Clusters'],axis=1)\n",
    "y=df[['Clusters']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.06944277,  0.04948308, -0.55118813, ...,  0.19333424,\n",
       "        -0.39626176, -0.5895595 ],\n",
       "       [-0.69232108,  0.15044095, -0.24433168, ...,  0.69860054,\n",
       "        -0.55697793, -0.07046797],\n",
       "       [-0.8380907 ,  0.28168617,  0.08840423, ...,  1.05336199,\n",
       "        -1.1355561 ,  0.44240689],\n",
       "       ...,\n",
       "       [-0.82163284, -0.71443142,  0.75387606, ...,  1.25761858,\n",
       "        -0.68555085,  1.98621204],\n",
       "       [-0.82868621,  0.77301444,  1.77796325, ...,  1.27911927,\n",
       "        -0.94912536,  3.16219783],\n",
       "       [-0.18447851, -0.2096421 , -1.13902157, ..., -0.13992651,\n",
       "         0.10517266, -0.59214978]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler=StandardScaler()\n",
    "x_train=scaler.fit_transform(x_train)\n",
    "x_test=scaler.transform(x_test)\n",
    "x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,recall_score,precision_score,f1_score,fbeta_score,classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "models={\n",
    "    'LR':LogisticRegression(),\n",
    "    'KNN':KNeighborsClassifier(),\n",
    "    'DT':DecisionTreeClassifier(),\n",
    "    'SVC':SVC(),\n",
    "    'NB':GaussianNB(),\n",
    "    'XGC':XGBClassifier(),\n",
    "    'RF':RandomForestClassifier()\n",
    "    \n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using LR: \n",
      "Training Accuracy :0.992\n",
      "Testing Accuracy :0.8571428571428571\n",
      "Confusion matrix:\n",
      " [[7 1 1 0 0 1]\n",
      " [0 8 0 0 0 0]\n",
      " [0 0 9 0 1 1]\n",
      " [0 0 0 0 0 1]\n",
      " [0 0 0 0 6 0]\n",
      " [0 0 0 0 0 6]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.70      0.82        10\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.90      0.82      0.86        11\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       0.86      1.00      0.92         6\n",
      "           7       0.67      1.00      0.80         6\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.72      0.75      0.72        42\n",
      "weighted avg       0.86      0.86      0.85        42\n",
      "\n",
      "---------------------------------\n",
      "using KNN: \n",
      "Training Accuracy :0.928\n",
      "Testing Accuracy :0.8809523809523809\n",
      "Confusion matrix:\n",
      " [[ 8  1  1  0  0  0]\n",
      " [ 0  8  0  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  0  0  0  6  0]\n",
      " [ 0  0  2  0  0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.80      0.89        10\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.79      1.00      0.88        11\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.80      0.67      0.73         6\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.75      0.74      0.74        42\n",
      "weighted avg       0.87      0.88      0.87        42\n",
      "\n",
      "---------------------------------\n",
      "using DT: \n",
      "Training Accuracy :1.0\n",
      "Testing Accuracy :0.8571428571428571\n",
      "Confusion matrix:\n",
      " [[8 1 1 0 0 0]\n",
      " [0 8 0 0 0 0]\n",
      " [2 0 9 0 0 0]\n",
      " [0 0 0 1 0 0]\n",
      " [0 0 0 0 6 0]\n",
      " [1 0 1 0 0 4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.80      0.76        10\n",
      "           1       0.89      1.00      0.94         8\n",
      "           2       0.82      0.82      0.82        11\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.67      0.80         6\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.91      0.88      0.89        42\n",
      "weighted avg       0.87      0.86      0.86        42\n",
      "\n",
      "---------------------------------\n",
      "using SVC: \n",
      "Training Accuracy :0.992\n",
      "Testing Accuracy :0.9047619047619048\n",
      "Confusion matrix:\n",
      " [[ 8  1  1  0  0  0]\n",
      " [ 1  7  0  0  0  0]\n",
      " [ 0  0 11  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 0  0  0  0  6  0]\n",
      " [ 0  0  1  0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.89      0.80      0.84        10\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.85      1.00      0.92        11\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       1.00      0.83      0.91         6\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.94      0.92      0.92        42\n",
      "weighted avg       0.91      0.90      0.90        42\n",
      "\n",
      "---------------------------------\n",
      "using NB: \n",
      "Training Accuracy :0.952\n",
      "Testing Accuracy :0.8571428571428571\n",
      "Confusion matrix:\n",
      " [[ 8  0  0  0  0  2]\n",
      " [ 0  8  0  0  0  0]\n",
      " [ 1  0 10  0  0  0]\n",
      " [ 0  0  1  0  0  0]\n",
      " [ 0  0  0  0  6  0]\n",
      " [ 1  0  1  0  0  4]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80        10\n",
      "           1       1.00      1.00      1.00         8\n",
      "           2       0.83      0.91      0.87        11\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.67      0.67      0.67         6\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.72      0.73      0.72        42\n",
      "weighted avg       0.84      0.86      0.85        42\n",
      "\n",
      "---------------------------------\n",
      "using XGC: \n",
      "[08:04:24] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :1.0\n",
      "Testing Accuracy :0.8571428571428571\n",
      "Confusion matrix:\n",
      " [[ 7  1  2  0  0  0]\n",
      " [ 0  7  0  0  0  1]\n",
      " [ 1  0 10  0  0  0]\n",
      " [ 0  0  0  1  0  0]\n",
      " [ 0  0  0  0  6  0]\n",
      " [ 0  0  1  0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.77      0.91      0.83        11\n",
      "           5       1.00      1.00      1.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.83      0.83      0.83         6\n",
      "\n",
      "    accuracy                           0.86        42\n",
      "   macro avg       0.89      0.89      0.89        42\n",
      "weighted avg       0.86      0.86      0.86        42\n",
      "\n",
      "---------------------------------\n",
      "using RF: \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :1.0\n",
      "Testing Accuracy :0.8333333333333334\n",
      "Confusion matrix:\n",
      " [[ 7  1  1  0  0  1]\n",
      " [ 0  7  0  0  0  1]\n",
      " [ 1  0 10  0  0  0]\n",
      " [ 0  0  0  0  0  1]\n",
      " [ 0  0  0  0  6  0]\n",
      " [ 0  0  1  0  0  5]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.70      0.78        10\n",
      "           1       0.88      0.88      0.88         8\n",
      "           2       0.83      0.91      0.87        11\n",
      "           5       0.00      0.00      0.00         1\n",
      "           6       1.00      1.00      1.00         6\n",
      "           7       0.62      0.83      0.71         6\n",
      "\n",
      "    accuracy                           0.83        42\n",
      "   macro avg       0.70      0.72      0.71        42\n",
      "weighted avg       0.83      0.83      0.82        42\n",
      "\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "for name,model in  models.items():\n",
    "    print(f'using {name}: ')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    print(f'Training Accuracy :{accuracy_score(y_train,model.predict(x_train))}')\n",
    "    print(f'Testing Accuracy :{accuracy_score(y_test,y_pred)}')\n",
    "    print(f'Confusion matrix:\\n {confusion_matrix(y_test,y_pred)}')\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('-'*33)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('datasets/Country-data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop('country',axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=scaler.fit_transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import scipy.cluster.hierarchy as sch\n",
    "dendrogram=sch.dendrogram(sch.linkage(x,method='ward'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "model=AgglomerativeClustering(n_clusters=3)\n",
    "cluster=model.fit_predict(x)\n",
    "df['Cluster']=cluster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "x=df.drop(['Cluster'],axis=1)\n",
    "y=df[['Cluster']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.25)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using LR: \n",
      "Training Accuracy :0.936\n",
      "Testing Accuracy :0.9047619047619048\n",
      "Confusion matrix:\n",
      " [[10  1  0]\n",
      " [ 1 27  0]\n",
      " [ 0  2  1]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.91      0.91      0.91        11\n",
      "           1       0.90      0.96      0.93        28\n",
      "           2       1.00      0.33      0.50         3\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.94      0.74      0.78        42\n",
      "weighted avg       0.91      0.90      0.89        42\n",
      "\n",
      "---------------------------------\n",
      "using KNN: \n",
      "Training Accuracy :0.872\n",
      "Testing Accuracy :0.8809523809523809\n",
      "Confusion matrix:\n",
      " [[ 9  2  0]\n",
      " [ 0 26  2]\n",
      " [ 0  1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.82      0.90        11\n",
      "           1       0.90      0.93      0.91        28\n",
      "           2       0.50      0.67      0.57         3\n",
      "\n",
      "    accuracy                           0.88        42\n",
      "   macro avg       0.80      0.80      0.79        42\n",
      "weighted avg       0.90      0.88      0.88        42\n",
      "\n",
      "---------------------------------\n",
      "using DT: \n",
      "Training Accuracy :1.0\n",
      "Testing Accuracy :0.9523809523809523\n",
      "Confusion matrix:\n",
      " [[11  0  0]\n",
      " [ 0 27  1]\n",
      " [ 0  1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.96      0.96      0.96        28\n",
      "           2       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.88      0.88      0.88        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n",
      "---------------------------------\n",
      "using SVC: \n",
      "Training Accuracy :0.776\n",
      "Testing Accuracy :0.9047619047619048\n",
      "Confusion matrix:\n",
      " [[10  1  0]\n",
      " [ 0 28  0]\n",
      " [ 0  3  0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.91      0.95        11\n",
      "           1       0.88      1.00      0.93        28\n",
      "           2       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.90        42\n",
      "   macro avg       0.62      0.64      0.63        42\n",
      "weighted avg       0.85      0.90      0.87        42\n",
      "\n",
      "---------------------------------\n",
      "using NB: \n",
      "Training Accuracy :0.936\n",
      "Testing Accuracy :0.9285714285714286\n",
      "Confusion matrix:\n",
      " [[11  0  0]\n",
      " [ 2 25  1]\n",
      " [ 0  0  3]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      1.00      0.92        11\n",
      "           1       1.00      0.89      0.94        28\n",
      "           2       0.75      1.00      0.86         3\n",
      "\n",
      "    accuracy                           0.93        42\n",
      "   macro avg       0.87      0.96      0.91        42\n",
      "weighted avg       0.94      0.93      0.93        42\n",
      "\n",
      "---------------------------------\n",
      "using XGC: \n",
      "[08:15:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:760: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:235: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "C:\\anaconda\\lib\\site-packages\\sklearn\\preprocessing\\_label.py:268: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy :1.0\n",
      "Testing Accuracy :0.9523809523809523\n",
      "Confusion matrix:\n",
      " [[11  0  0]\n",
      " [ 0 27  1]\n",
      " [ 0  1  2]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       0.96      0.96      0.96        28\n",
      "           2       0.67      0.67      0.67         3\n",
      "\n",
      "    accuracy                           0.95        42\n",
      "   macro avg       0.88      0.88      0.88        42\n",
      "weighted avg       0.95      0.95      0.95        42\n",
      "\n",
      "---------------------------------\n",
      "using RF: \n",
      "Training Accuracy :1.0\n",
      "Testing Accuracy :1.0\n",
      "Confusion matrix:\n",
      " [[11  0  0]\n",
      " [ 0 28  0]\n",
      " [ 0  0  3]]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\anaconda\\lib\\site-packages\\ipykernel_launcher.py:3: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        11\n",
      "           1       1.00      1.00      1.00        28\n",
      "           2       1.00      1.00      1.00         3\n",
      "\n",
      "    accuracy                           1.00        42\n",
      "   macro avg       1.00      1.00      1.00        42\n",
      "weighted avg       1.00      1.00      1.00        42\n",
      "\n",
      "---------------------------------\n"
     ]
    }
   ],
   "source": [
    "for name,model in  models.items():\n",
    "    print(f'using {name}: ')\n",
    "    model.fit(x_train,y_train)\n",
    "    y_pred=model.predict(x_test)\n",
    "    print(f'Training Accuracy :{accuracy_score(y_train,model.predict(x_train))}')\n",
    "    print(f'Testing Accuracy :{accuracy_score(y_test,y_pred)}')\n",
    "    print(f'Confusion matrix:\\n {confusion_matrix(y_test,y_pred)}')\n",
    "    \n",
    "    print(classification_report(y_test,y_pred))\n",
    "    print('-'*33)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
