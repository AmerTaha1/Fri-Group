{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import csv\n",
    "from bs4 import BeautifulSoup\n",
    "from functools import reduce\n",
    "url='https://books.toscrape.com/index.html'\n",
    "response=requests.get(url)\n",
    "soup=BeautifulSoup(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Travel_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[0].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Travel_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','w',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    writer.writerow(['Book_name','Price','Rate','Category'])\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Travel_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Mystery_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[1].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Mystery_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Mystery_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Historical_Fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[2].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Historical_Fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Historical_Fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Sequential_Art_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[3].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Sequential_Art_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Sequential_Art_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Classics_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[4].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Classics_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Classics_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Philosophy_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[5].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Philosophy_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Philosophy_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Romance_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[6].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Romance_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Romance_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Womens_Fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[7].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Womens_Fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Womens_Fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[8].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Childrens_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[9].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Childrens_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Childrens_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Religion_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[10].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Religion_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Religion_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Nonfiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[11].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Nonfiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Nonfiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Music_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[12].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Music_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Music_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Default_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[13].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Default_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Default_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Science_Fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[14].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Science_Fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Science_Fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Sports_and_Games_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[15].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Sports_and_Games_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Sports_and_Games_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Add_a_comment_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[16].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Add_a_comment_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Add_a_comment_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Fantasy_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[17].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Fantasy_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Fantasy_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "New_Adult_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[18].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(New_Adult_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,New_Adult_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Young_Adult_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[19].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Young_Adult_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Young_Adult_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Science_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[20].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Science_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Science_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Poetry_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[21].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Poetry_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Poetry_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Paranormal_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[22].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Paranormal_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Paranormal_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Art_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[23].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Art_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Art_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Psychology_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[24].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Psychology_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Psychology_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Autobiography_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[25].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Autobiography_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Autobiography_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Parenting_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[26].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Parenting_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Parenting_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Adult_Fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[27].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Adult_Fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Adult_Fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Humor_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[28].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Humor_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Humor_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Horror_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[29].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Horror_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Horror_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "History_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[30].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(History_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,History_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Food_and_Drink_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[31].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Food_and_Drink_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Food_and_Drink_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Christian_Fiction_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[32].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Christian_Fiction_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Christian_Fiction_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Business_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[33].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Business_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Business_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Biography_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[34].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Biography_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Biography_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Thriller_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[35].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Thriller_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Thriller_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Contemporary_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[36].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Contemporary_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Contemporary_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Spirituality_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[37].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Spirituality_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Spirituality_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Academic_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[38].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Academic_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Academic_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Self_Help_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[39].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Self_Help_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Self_Help_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Historical_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[40].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Historical_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Historical_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Christian_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[41].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Christian_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Christian_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Suspense_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[42].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Christian_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Suspense_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Short_Stories_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[43].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Short_Stories_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Short_Stories_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Novels_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[44].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Novels_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Novels_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Health_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[45].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Health_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Health_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Politics_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[46].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Politics_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Politics_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Cultural_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[47].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Cultural_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Cultural_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Erotica_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[48].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Erotica_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Erotica_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "domain='https://books.toscrape.com/'\n",
    "Crime_url=domain+soup.find('ul',attrs={'class':''}).find_all('li')[49].find('a').get('href')\n",
    "soup_cat=BeautifulSoup(requests.get(Crime_url).text,'html.parser')\n",
    "rates_dic={'Zero':0,'One':1,'Two':2,'Three':3,'Four':4,'Five':5}\n",
    "\n",
    "\n",
    "with open('books.csv','a',encoding='utf-8',newline='') as f:\n",
    "    writer=csv.writer(f)\n",
    "    category_name=soup_cat.find('title').get_text().strip().split('|')[0]\n",
    "    for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "        Book_name=article.find('h3').find('a').get('title')\n",
    "        Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "        Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "        writer.writerow([Book_name,Price,Rate,category_name])\n",
    "    while soup_cat.find('li',attrs={'class':'next'}):\n",
    "        new_page_url=reduce(lambda a,b:a+'/'+b,Crime_url.split('/')[:-1])+'/'+soup_cat.find('li',attrs={'class':'next'}).find('a').get('href')\n",
    "        soup_cat=BeautifulSoup(requests.get(new_page_url).text,'html.parser')\n",
    "        for article in soup_cat.find_all('article',attrs={'class':'product_pod'}):\n",
    "            Book_name=article.find('h3').find('a').get('title')\n",
    "            Price=float(article.find('div',attrs={'class':'product_price'}).find('p').get_text()[2:])\n",
    "            Rate=rates_dic[article.find('p').get('class')[1]]\n",
    "            writer.writerow([Book_name,Price,Rate,category_name])\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1002, 4)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('books.csv')\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
